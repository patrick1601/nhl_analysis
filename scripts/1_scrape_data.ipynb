{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Data\n",
    "In this module we are going to scrape nhl.com for all of the stats we need to train our machine learning model. NHL.com actually provides an API writted in JSON which will make it very easy to scrape. There is a great guide here https://github.com/dword4/nhlapi on how to navigate through and use the nhl API.\n",
    "\n",
    "You can see what the API looks like for a game at this link https://statsapi.web.nhl.com/api/v1/game/2021020797/feed/live. Buried in all that text is all the game information and stats we will need for our model.\n",
    "\n",
    "Using a JSON viewer will also make analyzing the JSON code a lot easier. When writing this code I used this one: http://jsonviewer.stack.hu/.\n",
    "\n",
    "We are eventually going to build 3 dataframes in order to train our model:\n",
    "1. Team stats dataframe - Will contain team stats each row will represent 1 team that played in a game\n",
    "2. Goalie stats dataframe - Will contain goalie stats each row will represent 1 goalie that played in a game\n",
    "3. Training dataframe - Will contain game information + team stats + goalie stats and will be used to train our model. Each row will represent 1 game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import pickle\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "#show full columns on dataframes\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option(\"display.max_rows\", 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Functions\n",
    "Our first step will be to write a few functions that will scrape the NHL.com API. \n",
    "\n",
    "Each NHL game has a unique game id used as an identifier. This function will take a season as an integer and return a list containing all game ids for that season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get game ids from nhl.com API\n",
    "def get_game_ids(season):\n",
    "    '''\n",
    "    Retrieves all of the game ids for the provided season\n",
    "    Arguments:\n",
    "        season (int): the season for which you want to retrieve game ids (ex: 20192020)\n",
    "    Returns:\n",
    "        List[int]: a list containing all regular season game ids for that season\n",
    "    '''\n",
    "\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "\n",
    "    season_str: str = str(season)\n",
    "    url: str = f\"https://statsapi.web.nhl.com/api/v1/schedule?season={season_str}&gameType=R\"\n",
    "    resp = session.get(url)\n",
    "    raw_schedule = json.loads(resp.text)\n",
    "    schedule = raw_schedule['dates']\n",
    "    # each entry in schedule is a day in the NHL. Each 'games' key contains games on that day\n",
    "    # Therefore we need a nested loop to retrieve all games\n",
    "\n",
    "    game_ids=[]\n",
    "\n",
    "    for day in schedule:\n",
    "        # Retrieve list that shows all games played on that day\n",
    "        games = day['games']\n",
    "        # Loop through games and retrieve ids\n",
    "        for game in games:\n",
    "            game_id = game['gamePk']\n",
    "            game_ids.append(game_id)\n",
    "    return game_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function will scrape the following data for both the home and away team for the game id provided:\n",
    "- Date game was played on\n",
    "- Home team\n",
    "- Away team\n",
    "- Goals scored\n",
    "- PIM's\n",
    "- Shots\n",
    "- PP%\n",
    "- PPG\n",
    "- PP Opportunities\n",
    "- FO%\n",
    "- Blocked Shots\n",
    "- Takeaways\n",
    "- Giveaways\n",
    "- Hits\n",
    "- Starting Goalies\n",
    "- Outcome\n",
    "\n",
    "The function will return a list containing 2 dictionaries. The first dictionary containing all the info for the home team and the second dictionary containing all the information for the away team.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team_stats(game_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "        returns two entries in a List.\n",
    "        The first entry is stats for the home team and the second is stats for the away team.\n",
    "        Each entry represents 1 game played.\n",
    "        Refer to: https://github.com/dword4/nhlapi on how to use the NHL API\n",
    "        Arguments\n",
    "            game_id (int): game id we are retrieving data for\n",
    "        Returns\n",
    "            List[dict]: list containing an entry for the home team and away team playing in the\n",
    "                        same game\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/game/{str(game_id)}/feed/live'\n",
    "    resp = session.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    # RETRIEVE STATS REQUIRED\n",
    "\n",
    "    # retrieve date and convert to date time\n",
    "    game_date: str = json_data['gameData']['datetime']['dateTime']\n",
    "    game_date = dt.datetime.strptime(game_date, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # Retrieve team names\n",
    "    home_team: str = json_data[\"liveData\"]['boxscore']['teams']['home']['team']['abbreviation']\n",
    "    away_team: str = json_data[\"liveData\"]['boxscore']['teams']['away']['team']['abbreviation']\n",
    "\n",
    "    # collect list of teamSkaterStats we want to retrieve from json data\n",
    "    team_skater_stats_home = json_data[\"liveData\"]\\\n",
    "        [\"boxscore\"]['teams']['home']['teamStats']['teamSkaterStats']\n",
    "    team_skater_stats_away = json_data[\"liveData\"]\\\n",
    "        [\"boxscore\"]['teams']['away']['teamStats']['teamSkaterStats']\n",
    "\n",
    "    # Starting goalies\n",
    "    # spot checked a few APIs and it seems like the starting goalie will be listed last in the json\n",
    "    # file if he was pulled. The goalie that finishes the game will be listed first (0).\n",
    "    home_team_starting_goalie_id = json_data[\"liveData\"]\\\n",
    "        ['boxscore']['teams']['home']['goalies'][-1]\n",
    "    away_team_starting_goalie_id = json_data[\"liveData\"]\\\n",
    "        ['boxscore']['teams']['away']['goalies'][-1]\n",
    "    home_team_starting_goalie_name = json_data[\"liveData\"]\\\n",
    "        ['boxscore']['teams']['home']['players']\\\n",
    "            ['ID'+str(home_team_starting_goalie_id)]['person']['fullName']\n",
    "    away_team_starting_goalie_name = json_data[\"liveData\"]\\\n",
    "        ['boxscore']['teams']['away']['players']\\\n",
    "            ['ID'+str(away_team_starting_goalie_id)]['person']['fullName']\n",
    "\n",
    "    # retrieve outcome (same for both home team and away team)\n",
    "    if not json_data['liveData']['linescore']['hasShootout']:\n",
    "        if (json_data[\"liveData\"][\"boxscore\"]\\\n",
    "            ['teams']['home']['teamStats']['teamSkaterStats']['goals'] >\n",
    "            json_data[\"liveData\"][\"boxscore\"]\\\n",
    "                ['teams']['away']['teamStats']['teamSkaterStats']['goals']):\n",
    "            home_team_win = True\n",
    "        if (json_data[\"liveData\"][\"boxscore\"]\\\n",
    "            ['teams']['home']['teamStats']['teamSkaterStats']['goals'] <\n",
    "            json_data[\"liveData\"][\"boxscore\"]\\\n",
    "                ['teams']['away']['teamStats']['teamSkaterStats']['goals']):\n",
    "            home_team_win = False\n",
    "    if json_data['liveData']['linescore']['hasShootout']:\n",
    "        if (json_data['liveData']['linescore']['shootoutInfo']['home']['scores'] >\n",
    "            json_data['liveData']['linescore']['shootoutInfo']['away']['scores']):\n",
    "            home_team_win = True\n",
    "        if (json_data['liveData']['linescore']['shootoutInfo']['home']['scores'] <\n",
    "            json_data['liveData']['linescore']['shootoutInfo']['away']['scores']):\n",
    "            home_team_win = False\n",
    "\n",
    "    # create dictionaries for the home and away team\n",
    "    if game_id == 2020020215: # manually entering incorrect input data in NHL API for this game\n",
    "        home_team_stats = {'date':game_date, 'game_id':game_id,\n",
    "                           'team':home_team, 'is_home_team':True,\n",
    "                           'home_team_win':False,\n",
    "                           'goalie_id':home_team_starting_goalie_id,\n",
    "                           'goalie_name':home_team_starting_goalie_name}\n",
    "\n",
    "        home_team_stats.update(team_skater_stats_home)\n",
    "\n",
    "        away_team_stats = {'date':game_date, 'game_id':game_id,\n",
    "                           'team':away_team, 'is_home_team':False,\n",
    "                           'home_team_win':False,\n",
    "                           'goalie_id':away_team_starting_goalie_id,\n",
    "                           'goalie_name':away_team_starting_goalie_name}\n",
    "\n",
    "        away_team_stats.update(team_skater_stats_away)\n",
    "\n",
    "    else:\n",
    "        home_team_stats = {'date':game_date, 'game_id':game_id,\n",
    "                           'team':home_team, 'is_home_team':True,\n",
    "                           'home_team_win':home_team_win,\n",
    "                           'goalie_id':home_team_starting_goalie_id,\n",
    "                           'goalie_name':home_team_starting_goalie_name}\n",
    "\n",
    "        home_team_stats.update(team_skater_stats_home)\n",
    "\n",
    "        away_team_stats = {'date':game_date, 'game_id':game_id,\n",
    "                           'team':away_team, 'is_home_team':False,\n",
    "                           'home_team_win':home_team_win,\n",
    "                           'goalie_id':away_team_starting_goalie_id,\n",
    "                           'goalie_name':away_team_starting_goalie_name}\n",
    "\n",
    "        away_team_stats.update(team_skater_stats_away)\n",
    "\n",
    "    teams = [home_team_stats, away_team_stats]\n",
    "\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run this function for one game so we can see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020797, 'team': 'TBL', 'is_home_team': True, 'home_team_win': True, 'goalie_id': 8476883, 'goalie_name': 'Andrei Vasilevskiy', 'goals': 3, 'pim': 10, 'shots': 32, 'powerPlayPercentage': '25.0', 'powerPlayGoals': 1.0, 'powerPlayOpportunities': 4.0, 'faceOffWinPercentage': '46.7', 'blocked': 10, 'takeaways': 4, 'giveaways': 4, 'hits': 37}, {'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020797, 'team': 'SJS', 'is_home_team': False, 'home_team_win': True, 'goalie_id': 8473503, 'goalie_name': 'James Reimer', 'goals': 2, 'pim': 12, 'shots': 21, 'powerPlayPercentage': '33.3', 'powerPlayGoals': 1.0, 'powerPlayOpportunities': 3.0, 'faceOffWinPercentage': '53.3', 'blocked': 11, 'takeaways': 6, 'giveaways': 1, 'hits': 43}]\n"
     ]
    }
   ],
   "source": [
    "data = scrape_team_stats(2021020797)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will scrape goalie stats. This function will take a game id and return a list containing a dictionary for each goalie that played in that game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_goalie_stats(game_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "        retrieves a list of dictionaries containing goalie stats for all\n",
    "        goalies that played in the game specified by game_id.\n",
    "        Each dictionary represents one goalie.\n",
    "        Refer to: https://github.com/dword4/nhlapi on how to use the NHL API\n",
    "        Arguments\n",
    "            game_id (int): game id we are retrieving data for\n",
    "        Returns\n",
    "            List[Dict]: list containing an entry for the home team and away team playing in the\n",
    "                        same game.\n",
    "        \"\"\"\n",
    "\n",
    "    # backoff strategy to avoid max retry errors\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/game/{str(game_id)}/feed/live'\n",
    "    resp = session.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    # RETRIEVE STATS REQUIRED\n",
    "\n",
    "    # get date\n",
    "    game_date = json_data['gameData']['datetime']['dateTime']\n",
    "    game_date = dt.datetime.strptime(game_date, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # Get goalie team\n",
    "    home_goalie_team = json_data['gameData']['teams']['home']['abbreviation']\n",
    "    away_goalie_team = json_data['gameData']['teams']['away']['abbreviation']\n",
    "\n",
    "    # Get goalie IDs\n",
    "    home_goalie_id = json_data['liveData']['boxscore']['teams']['home']['goalies']\n",
    "    away_goalie_id = json_data['liveData']['boxscore']['teams']['away']['goalies']\n",
    "\n",
    "    # Get goalie names\n",
    "    home_goalie_names = []\n",
    "    away_goalie_names = []\n",
    "\n",
    "    # for loop to iterate through list of home goalies that played this game\n",
    "    for i in home_goalie_id:\n",
    "        j = json_data['liveData']['boxscore']['teams']['home']['players']['ID' + str(i)]\\\n",
    "            ['person']['fullName']\n",
    "        home_goalie_names.append(j)\n",
    "    # for loop to iterate through list of away goalies that played this game\n",
    "    for i in away_goalie_id:\n",
    "        j = json_data['liveData']['boxscore']['teams']['away']['players']['ID' + str(i)]\\\n",
    "            ['person']['fullName']\n",
    "        away_goalie_names.append(j)\n",
    "\n",
    "    # Get goalie stats\n",
    "    home_goalie_stats = []\n",
    "    away_goalie_stats = []\n",
    "    # for loop to iterate through list of home goalies that played this game\n",
    "    for i in home_goalie_id:\n",
    "        j = json_data['liveData']['boxscore']['teams']['home']['players']['ID' + str(i)]\\\n",
    "            ['stats']['goalieStats']\n",
    "        home_goalie_stats.append(j)\n",
    "    # for loop to iterate through list of home goalies that played this game\n",
    "    for i in away_goalie_id:\n",
    "        j = json_data['liveData']['boxscore']['teams']['away']['players']['ID' + str(i)]\\\n",
    "            ['stats']['goalieStats']\n",
    "        away_goalie_stats.append(j)\n",
    "\n",
    "    # make home goalie list. for loop needed as there could be more than 2 goalies playing in 1 game\n",
    "    home_goalies = []\n",
    "    goalie_counter = list(range(len(home_goalie_stats))) # counter for number of goalies that played\n",
    "\n",
    "    for goalie_count in goalie_counter:\n",
    "        # create dictonary for goalie\n",
    "        home_goalie = {'date':game_date, 'game_id':game_id, 'team':home_goalie_team,\n",
    "                       'goalie_name':home_goalie_names[goalie_count],\\\n",
    "                           'goalie_id':home_goalie_id[goalie_count],\n",
    "                       'is_home_team':True}\n",
    "        home_goalie.update(home_goalie_stats[goalie_count])\n",
    "\n",
    "        home_goalies.append(home_goalie)\n",
    "\n",
    "    # make away goalie list. for loop needed as there could be more than 2 goalies playing in 1 game\n",
    "    away_goalies = []\n",
    "    goalie_counter = list(range(len(away_goalie_stats))) # counter for number of goalies that played\n",
    "\n",
    "    for goalie_count in goalie_counter:\n",
    "        # create dictonary for goalie\n",
    "        away_goalie = {'date':game_date, 'game_id':game_id, 'team':away_goalie_team,\n",
    "                       'goalie_name':away_goalie_names[goalie_count],\\\n",
    "                           'goalie_id':away_goalie_id[goalie_count],\n",
    "                       'is_home_team':False}\n",
    "        away_goalie.update(away_goalie_stats[goalie_count])\n",
    "\n",
    "        away_goalies.append(away_goalie)\n",
    "\n",
    "\n",
    "    # Merge the two lists\n",
    "    goalie_stats = away_goalies + home_goalies\n",
    "\n",
    "    return goalie_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try this function for one game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020797, 'team': 'SJS', 'goalie_name': 'James Reimer', 'goalie_id': 8473503, 'is_home_team': False, 'timeOnIce': '62:45', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 32, 'saves': 29, 'powerPlaySaves': 3, 'shortHandedSaves': 0, 'evenSaves': 26, 'shortHandedShotsAgainst': 0, 'evenShotsAgainst': 28, 'powerPlayShotsAgainst': 4, 'decision': 'L', 'savePercentage': 90.625, 'powerPlaySavePercentage': 75.0, 'evenStrengthSavePercentage': 92.85714285714286}, {'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020797, 'team': 'TBL', 'goalie_name': 'Andrei Vasilevskiy', 'goalie_id': 8476883, 'is_home_team': True, 'timeOnIce': '62:45', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 21, 'saves': 19, 'powerPlaySaves': 4, 'shortHandedSaves': 1, 'evenSaves': 14, 'shortHandedShotsAgainst': 1, 'evenShotsAgainst': 15, 'powerPlayShotsAgainst': 5, 'decision': 'W', 'savePercentage': 90.47619047619048, 'powerPlaySavePercentage': 80.0, 'shortHandedSavePercentage': 100.0, 'evenStrengthSavePercentage': 93.33333333333333}]\n"
     ]
    }
   ],
   "source": [
    "data = scrape_goalie_stats(2021020797)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a goalie gets pulled we should make sure that all goalies are scrapped for that game. Lets try a game where there was a pulled goalie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020798, 'team': 'TOR', 'goalie_name': 'Jack Campbell', 'goalie_id': 8475789, 'is_home_team': False, 'timeOnIce': '60:00', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 32, 'saves': 31, 'powerPlaySaves': 4, 'shortHandedSaves': 1, 'evenSaves': 26, 'shortHandedShotsAgainst': 1, 'evenShotsAgainst': 27, 'powerPlayShotsAgainst': 4, 'decision': 'W', 'savePercentage': 96.875, 'powerPlaySavePercentage': 100.0, 'shortHandedSavePercentage': 100.0, 'evenStrengthSavePercentage': 96.29629629629629}, {'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020798, 'team': 'NJD', 'goalie_name': 'Jon Gillies', 'goalie_id': 8476903, 'is_home_team': True, 'timeOnIce': '40:00', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 28, 'saves': 22, 'powerPlaySaves': 2, 'shortHandedSaves': 1, 'evenSaves': 19, 'shortHandedShotsAgainst': 1, 'evenShotsAgainst': 25, 'powerPlayShotsAgainst': 2, 'decision': 'L', 'savePercentage': 78.57142857142857, 'powerPlaySavePercentage': 100.0, 'shortHandedSavePercentage': 100.0, 'evenStrengthSavePercentage': 76.0}, {'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020798, 'team': 'NJD', 'goalie_name': 'Akira Schmid', 'goalie_id': 8481033, 'is_home_team': True, 'timeOnIce': '20:00', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 8, 'saves': 7, 'powerPlaySaves': 0, 'shortHandedSaves': 0, 'evenSaves': 7, 'shortHandedShotsAgainst': 0, 'evenShotsAgainst': 8, 'powerPlayShotsAgainst': 0, 'decision': '', 'savePercentage': 87.5, 'evenStrengthSavePercentage': 87.5}]\n"
     ]
    }
   ],
   "source": [
    "data = scrape_goalie_stats(2021020798)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect we can see in this game there are 3 dictionaries in the list representing all 3 goalies that played in the game.\n",
    "\n",
    "This next function will pull game information. It will take a game id and return a dictionary contianing game information for that game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game_info(game_id:int) -> Dict:\n",
    "    \"\"\"\n",
    "        returns an dictionary with game information for the game_id provided\n",
    "        Refer to: https://github.com/dword4/nhlapi on how to use the NHL API\n",
    "        Arguments\n",
    "            game_id (int): game id we are retrieving data for\n",
    "        Returns\n",
    "            Dict: Dictionary with information for the game_id provided\n",
    "        \"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/game/{str(game_id)}/feed/live'\n",
    "    resp = session.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    # RETRIEVE INFO REQUIRED\n",
    "\n",
    "    # retrieve date and convert to date time\n",
    "    game_date: str = json_data['gameData']['datetime']['dateTime']\n",
    "    game_date = dt.datetime.strptime(game_date, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # Retrieve team names\n",
    "    home_team: str = json_data[\"liveData\"]['boxscore']['teams']['home']['team']['abbreviation']\n",
    "    away_team: str = json_data[\"liveData\"]['boxscore']['teams']['away']['team']['abbreviation']\n",
    "\n",
    "    # retrieve outcome 'hasShootout' is a boolean\n",
    "    if not json_data['liveData']['linescore']['hasShootout']:\n",
    "        if json_data[\"liveData\"][\"boxscore\"]['teams']['home']['teamStats']['teamSkaterStats']\\\n",
    "            ['goals'] > json_data[\"liveData\"][\"boxscore\"]['teams']['away']['teamStats']\\\n",
    "                ['teamSkaterStats']['goals']:\n",
    "            home_team_win = True\n",
    "        if json_data[\"liveData\"][\"boxscore\"]['teams']['home']['teamStats']['teamSkaterStats']\\\n",
    "            ['goals'] < json_data[\"liveData\"][\"boxscore\"]['teams']['away']['teamStats']\\\n",
    "                ['teamSkaterStats']['goals']:\n",
    "            home_team_win = False\n",
    "    if json_data['liveData']['linescore']['hasShootout']:\n",
    "        if json_data['liveData']['linescore']['shootoutInfo']['home']['scores'] >\\\n",
    "            json_data['liveData']['linescore']['shootoutInfo']['away']['scores']:\n",
    "            home_team_win = True\n",
    "        if json_data['liveData']['linescore']['shootoutInfo']['home']['scores'] <\\\n",
    "            json_data['liveData']['linescore']['shootoutInfo']['away']['scores']:\n",
    "            home_team_win = False\n",
    "\n",
    "    # Starting goalies\n",
    "    # spot checked a few APIs and it seems like the starting goalie will be listed last in the json\n",
    "    # file if he was pulled. The goalie that finishes the game will be listed first (0).\n",
    "    home_team_starting_goalie_id = json_data[\"liveData\"]['boxscore']['teams']['home']['goalies'][-1]\n",
    "    away_team_starting_goalie_id = json_data[\"liveData\"]['boxscore']['teams']['away']['goalies'][-1]\n",
    "    home_team_starting_goalie_name = \\\n",
    "    json_data[\"liveData\"]['boxscore']['teams']['home']['players']['ID' +\\\n",
    "        str(home_team_starting_goalie_id)]['person']['fullName']\n",
    "    away_team_starting_goalie_name = \\\n",
    "    json_data[\"liveData\"]['boxscore']['teams']['away']['players']['ID' +\\\n",
    "        str(away_team_starting_goalie_id)]['person']['fullName']\n",
    "    if game_id == 2020020215: # manually entering incorrect input data in NHL API for this game\n",
    "        game_info = {'date':game_date, 'game_id':game_id, 'home_team':home_team,\\\n",
    "            'away_team':away_team, 'home_team_win':False,\\\n",
    "                'home_goalie_id':home_team_starting_goalie_id,\\\n",
    "                    'away_goalie_id':away_team_starting_goalie_id,\\\n",
    "                        'home_goalie_name':home_team_starting_goalie_name,\\\n",
    "                            'away_goalie_name':away_team_starting_goalie_name}\n",
    "    else:\n",
    "        game_info = {'date':game_date, 'game_id':game_id, 'home_team':home_team,\\\n",
    "            'away_team':away_team, 'home_team_win':home_team_win,\\\n",
    "                'home_goalie_id':home_team_starting_goalie_id,\\\n",
    "                    'away_goalie_id':away_team_starting_goalie_id,\\\n",
    "                        'home_goalie_name':home_team_starting_goalie_name,\\\n",
    "                            'away_goalie_name':away_team_starting_goalie_name}\n",
    "    return game_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run an example game id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': datetime.datetime(2022, 2, 2, 0, 0), 'game_id': 2021020798, 'home_team': 'NJD', 'away_team': 'TOR', 'home_team_win': False, 'home_goalie_id': 8481033, 'away_goalie_id': 8475789, 'home_goalie_name': 'Akira Schmid', 'away_goalie_name': 'Jack Campbell'}\n"
     ]
    }
   ],
   "source": [
    "print(scrape_game_info(2021020798))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now written our main scrapping functions. We'll just need a few helper functions that will help us along the way. This first function will take a game ID and retrieve a team playing in that game depending on the boolean supplied as the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_team(game_id: int, home: bool) -> str:\n",
    "    \"\"\"\n",
    "    retrieves the team abbreviation playing in an NHL game\n",
    "    Arguments\n",
    "        game_id (int): game id we are retrieving data for\n",
    "        home (bool): if True retrieves the home team, False retrieves away\n",
    "    Returns\n",
    "        team (str): team abbreviation\n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/game/{str(game_id)}/feed/live'\n",
    "    resp = requests.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    if home:\n",
    "        team = json_data['gameData']['teams']['home']['abbreviation']\n",
    "    else:\n",
    "        team = json_data['gameData']['teams']['away']['abbreviation']\n",
    "\n",
    "    return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NJD'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_team(2021020798, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOR'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_team(2021020798, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will take a game id and retrieve the date that game was played on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_date(game_id: int) -> dt.datetime:\n",
    "    \"\"\"\n",
    "    retrieves the date an NHL game was played\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    game_id: int\n",
    "        game id we are retrieving data for\n",
    "    Returns\n",
    "    -------\n",
    "    date: dt.datetime\n",
    "        date that NHL game was played\n",
    "    \"\"\"\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/game/{str(game_id)}/feed/live'\n",
    "    resp = requests.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    date = json_data['gameData']['datetime']['dateTime']\n",
    "    date = dt.datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    # The NHL api applies an offset to the date which messes with the time we need to \n",
    "    # subtract this offset from the date\n",
    "\n",
    "    offset = int(json_data['gameData']['teams']['home']['venue']['timeZone']['offset'])\n",
    "\n",
    "    date = date + timedelta(hours=offset)\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 2, 1, 19, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_date(2021020804)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting goalies are very important in the NHL and in order to make accurate predictions we will need to predict the starting goalies for each game. The following function will go to dailyfaceoff.com and scrape the predicted starting goalies for a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_goalies(home_abv: str, away_abv: str, date: str) -> str:\n",
    "    \"\"\"\n",
    "    scrapes starting goaltenders from dailyfaceoff.com for the specified date and teams\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    home_abv: str\n",
    "        abbreviation for home team\n",
    "    away_abv: str\n",
    "        abbreviation for away team\n",
    "    date: str\n",
    "        string for which we want to retrieve starting goalies (ex. '01-13-2021')\n",
    "    Returns\n",
    "    -------\n",
    "    home_goalie: str\n",
    "        home goalie name\n",
    "    away_goalie: str\n",
    "        away goalie name\n",
    "    \"\"\"\n",
    "\n",
    "    # First define a dictionary to translate team abbreviations\n",
    "    # in our df to the team names used on daily faceoff\n",
    "    team_translations = {'MIN':'Minnesota Wild','TOR':'Toronto Maple Leafs',\n",
    "                         'PIT':'Pittsburgh Penguins', 'COL':'Colorado Avalanche',\n",
    "                         'EDM':'Edmonton Oilers', 'CAR':'Carolina Hurricanes',\n",
    "                         'CBJ':'Columbus Blue Jackets', 'NJD':'New Jersey Devils',\n",
    "                         'DET':'Detroit Red Wings', 'OTT':'Ottawa Senators',\n",
    "                         'BOS':'Boston Bruins', 'SJS':'San Jose Sharks',\n",
    "                         'BUF':'Buffalo Sabres','NYI':'New York Islanders',\n",
    "                         'WSH':'Washington Capitals','TBL':'Tampa Bay Lightning',\n",
    "                         'STL':'St Louis Blues', 'NSH':'Nashville Predators',\n",
    "                         'CHI':'Chicago Blackhawks', 'VAN':'Vancouver Canucks',\n",
    "                         'CGY':'Calgary Flames', 'PHI':'Philadelphia Flyers',\n",
    "                         'LAK':'Los Angeles Kings', 'MTL':'Montreal Canadiens',\n",
    "                         'ANA':'Anaheim Ducks', 'DAL':'Dallas Stars',\n",
    "                         'NYR':'New York Rangers', 'FLA':'Florida Panthers',\n",
    "                         'WPG':'Winnipeg Jets', 'ARI':'Arizona Coyotes',\n",
    "                         'VGK':'Vegas Golden Knights'}\n",
    "\n",
    "    home_team = team_translations[home_abv]\n",
    "    away_team = team_translations[away_abv]\n",
    "\n",
    "    url = f'https://www.dailyfaceoff.com/starting-goalies/{date}'\n",
    "\n",
    "    # Need headers as daily faceoff will block the get request without one\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6)\\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36'}\n",
    "    result = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the data\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "    goalie_boxes = soup.find_all('div', {'class':'starting-goalies-card stat-card'})\n",
    "\n",
    "    # find the goalie box that contains the games we are looking for\n",
    "    for count, box in enumerate(goalie_boxes):\n",
    "        if home_team and away_team in box.text:\n",
    "            goalie_box = goalie_boxes[count]\n",
    "        else:\n",
    "            continue\n",
    "    # retrieve the h4 headings which contain the starting goalies\n",
    "\n",
    "    h4_headings = goalie_box.find_all('h4')\n",
    "\n",
    "    # Away goalie is at element 1 and home goalie is at element 2\n",
    "    away_goalie = h4_headings[1].text\n",
    "    home_goalie = h4_headings[2].text\n",
    "\n",
    "    return home_goalie, away_goalie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each player in the nhl has a unique numeric ID. Once we have the starting goalie names from daily faceoff we need to convert the name to the numeric ID used by the nhl.com website to identify the player. The following function will accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_player_to_id(team_name: str, player_name: str):\n",
    "    \"\"\"\n",
    "    converts a player name to id\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    team_name: str\n",
    "        abbreviation for the players team\n",
    "    player_name: str\n",
    "        player name string. first and last name (ex. 'Olli Jokinen')\n",
    "    Returns\n",
    "    -------\n",
    "    player_id: int\n",
    "        player id\n",
    "    \"\"\"\n",
    "    url = 'https://statsapi.web.nhl.com/api/v1/teams'\n",
    "    resp = requests.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    for team in json_data['teams']:\n",
    "        if team['abbreviation'] == team_name:\n",
    "            team_id = team['id']\n",
    "        else:\n",
    "            continue\n",
    "    # Use the team id to go to team page\n",
    "    url = f'https://statsapi.web.nhl.com/api/v1/teams/{team_id}?expand=team.roster'\n",
    "    resp = requests.get(url)\n",
    "    json_data = json.loads(resp.text)\n",
    "\n",
    "    team_roster = json_data['teams'][0]['roster']['roster']\n",
    "\n",
    "    for player_info in team_roster:\n",
    "        if player_info['person']['fullName'] == player_name:\n",
    "            return player_info['person']['id']\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Scrape\n",
    "Now that we have all our scraping functions it's time to scrape the date we need. \n",
    "\n",
    "### Scrape Game IDs\n",
    "We are going to scrape all games between 2012 and 2020. First we will get a list of game ids for all of these games. Since we don't want to be constantly scraping data we will store this data in a pickle file in our data folder so we always have it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_game_ids(first_year: int=2012, last_year: int=2020) -> List[int]:\n",
    "    \"\"\"\n",
    "    pulls all nhl game ids between the specified dates\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    first_year: int\n",
    "        first year to retrieve game ids\n",
    "    last_year: int\n",
    "        last year to retrieve game ids\n",
    "    Returns\n",
    "    -------\n",
    "    game_ids: str\n",
    "    \"\"\"\n",
    "    #create a list of years for which we want data\n",
    "    years = list(range(first_year, last_year))\n",
    "\n",
    "    #create year for the get_game_ids() function argument in the format 20192020\n",
    "    game_ids_url_years = []\n",
    "\n",
    "    for i in years:\n",
    "        j = str(i) + str(i+1)\n",
    "        game_ids_url_years.append(j)\n",
    "\n",
    "    #run for loop to retrieve game IDs for all seasons required\n",
    "    ids = []\n",
    "    for i in game_ids_url_years:\n",
    "\n",
    "        if len(ids) % 500 == 0:  # Progress bar\n",
    "            print(str(len(ids) / len(game_ids_url_years) * 100) +\n",
    "                  ' percent done retrieving game ids.')\n",
    "\n",
    "        try:\n",
    "            ids = ids + get_game_ids(i)\n",
    "\n",
    "        except KeyError:\n",
    "            print(str('*************Not able to retrieve: ' +\n",
    "                      str(i) +\n",
    "                      ' games due to KeyError************'))\n",
    "            continue\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 percent done retrieving game ids.\n",
      "[2012020001, 2012020002, 2012020003, 2012020004, 2012020005, 2012020006, 2012020007, 2012020008, 2012020009, 2012020010]\n",
      "[2020020688, 2020020790, 2020020803, 2020020647, 2020020704, 2020020741, 2020020673, 2020020567, 2020020864, 2020020634]\n",
      "10144 Game Ids were retrieved\n"
     ]
    }
   ],
   "source": [
    "#%% scrape game ids\n",
    "game_ids = pull_game_ids(first_year=2012, last_year=2021)\n",
    "with open('/Users/patrickpetanca/projects/nhl_analysis/data/game_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(game_ids, f)\n",
    "\n",
    "print(game_ids[0:10])\n",
    "print(game_ids[-10:])\n",
    "print(str(len(game_ids)) + ' Game Ids were retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the first and last 10 elements of the list and everything looks good. The first 4 digits of the gameid tell you the year, the 02 after means it was a regular season game and the last digits tell you the game number of the season it was.\n",
    "\n",
    "10144 ids were retrieved and with some rough math that is about what we would expect for 9 years of hockey.\n",
    "\n",
    "### Scrape Team Stats\n",
    "Now lets write a function to pull our team stats for every game in our game_ids list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% scrape team stats\n",
    "def pull_team_stats(ids: List[int]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    pulls all team stats for the provided game ids\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    ids: List[int]\n",
    "        list of game ids to pull team stats for\n",
    "    Returns\n",
    "    -------\n",
    "    team_stats: List[dict]\n",
    "        list of NhlTeam objects\n",
    "    \"\"\"\n",
    "\n",
    "    # retrieve game by game stats for every game in the ids list\n",
    "    stats = []\n",
    "\n",
    "    for i in ids:\n",
    "        stats_i = scrape_team_stats(i)\n",
    "        stats += stats_i\n",
    "\n",
    "        if len(stats) % 500 == 0:  # Progress bar\n",
    "            print(str(0.5 * len(stats) /\n",
    "                      len(ids) * 100) +\n",
    "                  ' percent done retrieving game data/stats.')\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull team stats and store them in a pickle file. The following cell will take approximately an hour to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4645110410094637 percent done retrieving game data/stats.\n",
      "4.929022082018927 percent done retrieving game data/stats.\n",
      "7.393533123028391 percent done retrieving game data/stats.\n",
      "9.858044164037855 percent done retrieving game data/stats.\n",
      "12.322555205047319 percent done retrieving game data/stats.\n",
      "14.787066246056781 percent done retrieving game data/stats.\n",
      "17.251577287066247 percent done retrieving game data/stats.\n",
      "19.71608832807571 percent done retrieving game data/stats.\n",
      "22.180599369085176 percent done retrieving game data/stats.\n",
      "24.645110410094638 percent done retrieving game data/stats.\n",
      "27.1096214511041 percent done retrieving game data/stats.\n",
      "29.574132492113563 percent done retrieving game data/stats.\n",
      "32.03864353312303 percent done retrieving game data/stats.\n",
      "34.503154574132495 percent done retrieving game data/stats.\n",
      "36.967665615141954 percent done retrieving game data/stats.\n",
      "39.43217665615142 percent done retrieving game data/stats.\n",
      "41.896687697160885 percent done retrieving game data/stats.\n",
      "44.36119873817035 percent done retrieving game data/stats.\n",
      "46.82570977917981 percent done retrieving game data/stats.\n",
      "49.290220820189276 percent done retrieving game data/stats.\n",
      "51.754731861198735 percent done retrieving game data/stats.\n",
      "54.2192429022082 percent done retrieving game data/stats.\n",
      "56.68375394321766 percent done retrieving game data/stats.\n",
      "59.148264984227126 percent done retrieving game data/stats.\n",
      "61.61277602523659 percent done retrieving game data/stats.\n",
      "64.07728706624606 percent done retrieving game data/stats.\n",
      "66.54179810725552 percent done retrieving game data/stats.\n",
      "69.00630914826499 percent done retrieving game data/stats.\n",
      "71.47082018927445 percent done retrieving game data/stats.\n",
      "73.93533123028391 percent done retrieving game data/stats.\n",
      "76.39984227129337 percent done retrieving game data/stats.\n",
      "78.86435331230284 percent done retrieving game data/stats.\n",
      "81.3288643533123 percent done retrieving game data/stats.\n",
      "83.79337539432177 percent done retrieving game data/stats.\n",
      "86.25788643533123 percent done retrieving game data/stats.\n",
      "88.7223974763407 percent done retrieving game data/stats.\n",
      "91.18690851735016 percent done retrieving game data/stats.\n",
      "93.65141955835962 percent done retrieving game data/stats.\n",
      "96.11593059936908 percent done retrieving game data/stats.\n",
      "98.58044164037855 percent done retrieving game data/stats.\n"
     ]
    }
   ],
   "source": [
    "#%% scrape team stats\n",
    "team_stats = pull_team_stats(game_ids)\n",
    "with open('/Users/patrickpetanca/projects/nhl_analysis/data/team_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(team_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one entry in this data list looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20288\n",
      "{'date': datetime.datetime(2013, 1, 19, 20, 0), 'game_id': 2012020001, 'team': 'PHI', 'is_home_team': True, 'home_team_win': False, 'goalie_id': 8468524, 'goalie_name': 'Ilya Bryzgalov', 'goals': 1, 'pim': 6, 'shots': 27, 'powerPlayPercentage': '0.0', 'powerPlayGoals': 0.0, 'powerPlayOpportunities': 5.0, 'faceOffWinPercentage': '43.5', 'blocked': 12, 'takeaways': 8, 'giveaways': 12, 'hits': 40}\n"
     ]
    }
   ],
   "source": [
    "print(len(team_stats))\n",
    "print(team_stats[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 20288 dictionaries in our list which is exactly double the amount of game_ids we pulled. This makes sense as there are 2 teams playing in each game.\n",
    "\n",
    "### Scrape Goalie Stats\n",
    "The below function will now scrape goalie stats our goalie stast and store them in a list of dictionaries. Each dictionary in the list represents stats for 1 goalie in 1 game. We will again store the information in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% scrape goalie stats\n",
    "def pull_goalie_stats(ids: List[int]) -> List[dict]:\n",
    "    \"\"\"\n",
    "        pulls all goalie stats for the provided game ids\n",
    "        ...\n",
    "        Parameters\n",
    "        ----------\n",
    "        game_ids: List[int]\n",
    "            list of game ids to pull team stats for\n",
    "        Returns\n",
    "        -------\n",
    "        goalie_stats: List[dict]\n",
    "            list of nhl goalie dictionaries each entry\n",
    "            represents 1 game played by 1 goalie\n",
    "        \"\"\"\n",
    "\n",
    "    goalie_stats_list=[]\n",
    "    for i in ids:\n",
    "        goalies_i = scrape_goalie_stats(i)\n",
    "        goalie_stats_list += goalies_i\n",
    "\n",
    "        # progress bar todo fix progress bar to account for more goalies than game ids\n",
    "        if len(goalie_stats_list) % 250 == 0:\n",
    "            print(str(0.5 * len(goalie_stats_list) /\n",
    "                      len(ids) * 100) +\n",
    "                  ' percent done retrieving goalie data.')\n",
    "\n",
    "    return goalie_stats_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the stats. Again this will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6967665615141954 percent done retrieving goalie data.\n",
      "9.858044164037855 percent done retrieving goalie data.\n",
      "12.322555205047319 percent done retrieving goalie data.\n",
      "13.55481072555205 percent done retrieving goalie data.\n",
      "16.019321766561514 percent done retrieving goalie data.\n",
      "20.948343848580443 percent done retrieving goalie data.\n",
      "23.412854889589905 percent done retrieving goalie data.\n",
      "24.645110410094638 percent done retrieving goalie data.\n",
      "27.1096214511041 percent done retrieving goalie data.\n",
      "32.03864353312303 percent done retrieving goalie data.\n",
      "36.967665615141954 percent done retrieving goalie data.\n",
      "41.896687697160885 percent done retrieving goalie data.\n",
      "43.128943217665615 percent done retrieving goalie data.\n",
      "44.36119873817035 percent done retrieving goalie data.\n",
      "46.82570977917981 percent done retrieving goalie data.\n",
      "49.290220820189276 percent done retrieving goalie data.\n",
      "52.986987381703464 percent done retrieving goalie data.\n",
      "55.45149842271293 percent done retrieving goalie data.\n",
      "56.68375394321766 percent done retrieving goalie data.\n",
      "61.61277602523659 percent done retrieving goalie data.\n",
      "66.54179810725552 percent done retrieving goalie data.\n",
      "69.00630914826499 percent done retrieving goalie data.\n",
      "72.70307570977917 percent done retrieving goalie data.\n",
      "73.93533123028391 percent done retrieving goalie data.\n",
      "75.16758675078864 percent done retrieving goalie data.\n",
      "76.39984227129337 percent done retrieving goalie data.\n",
      "77.6320977917981 percent done retrieving goalie data.\n",
      "78.86435331230284 percent done retrieving goalie data.\n",
      "81.3288643533123 percent done retrieving goalie data.\n",
      "85.0256309148265 percent done retrieving goalie data.\n",
      "87.49014195583597 percent done retrieving goalie data.\n",
      "92.4191640378549 percent done retrieving goalie data.\n",
      "94.88367507886434 percent done retrieving goalie data.\n",
      "96.11593059936908 percent done retrieving goalie data.\n",
      "98.58044164037855 percent done retrieving goalie data.\n",
      "101.04495268138803 percent done retrieving goalie data.\n",
      "102.27720820189275 percent done retrieving goalie data.\n",
      "103.50946372239747 percent done retrieving goalie data.\n",
      "104.7417192429022 percent done retrieving goalie data.\n",
      "105.97397476340693 percent done retrieving goalie data.\n",
      "107.20623028391168 percent done retrieving goalie data.\n"
     ]
    }
   ],
   "source": [
    "#%% scrape goalie stats\n",
    "goalie_stats = pull_goalie_stats(game_ids)\n",
    "with open('/Users/patrickpetanca/projects/nhl_analysis/data/goalie_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(goalie_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one entry in this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': datetime.datetime(2013, 1, 19, 20, 0), 'game_id': 2012020001, 'team': 'PIT', 'goalie_name': 'Marc-Andre Fleury', 'goalie_id': 8470594, 'is_home_team': False, 'timeOnIce': '60:00', 'assists': 0, 'goals': 0, 'pim': 0, 'shots': 27, 'saves': 26, 'powerPlaySaves': 11, 'shortHandedSaves': 0, 'evenSaves': 15, 'shortHandedShotsAgainst': 0, 'evenShotsAgainst': 16, 'powerPlayShotsAgainst': 11, 'decision': 'W', 'savePercentage': 96.29629629629629, 'powerPlaySavePercentage': 100.0, 'evenStrengthSavePercentage': 93.75}\n",
      "21820\n"
     ]
    }
   ],
   "source": [
    "print(goalie_stats[0])\n",
    "print(len(goalie_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Games Info\n",
    "Finally we will scrape game information. This information is the start of the data we will use to train our machine learning model. We will append a bunch of stats to the end of the data frame and use that for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% scrape game info\n",
    "def pull_game_info(ids: List[int]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    pulls all game_info for the provided game ids\n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    ids: List[int]\n",
    "        list of game ids to pull team stats for\n",
    "    Returns\n",
    "    -------\n",
    "    games_info: List[dict]\n",
    "        list of dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    # retrieve game by game info for every game in the game_ids list\n",
    "    games_info = []\n",
    "\n",
    "    for i in ids:\n",
    "        game_i = scrape_game_info(i)\n",
    "        games_info.append(game_i)\n",
    "\n",
    "        if len(games_info) % 500 == 0:  # Progress bar\n",
    "            print(str(len(games_info) /\n",
    "                      len(ids) * 100) +\n",
    "                  ' percent done retrieving game data/stats.')\n",
    "    return games_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.929022082018927 percent done retrieving game data/stats.\n",
      "9.858044164037855 percent done retrieving game data/stats.\n",
      "14.787066246056781 percent done retrieving game data/stats.\n",
      "19.71608832807571 percent done retrieving game data/stats.\n",
      "24.645110410094638 percent done retrieving game data/stats.\n",
      "29.574132492113563 percent done retrieving game data/stats.\n",
      "34.503154574132495 percent done retrieving game data/stats.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb Cell 47'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000047?line=0'>1</a>\u001b[0m \u001b[39m#%% scrape game info\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000047?line=1'>2</a>\u001b[0m game_info \u001b[39m=\u001b[39m pull_game_info(game_ids)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000047?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/patrickpetanca/projects/nhl_analysis/data/games_info.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000047?line=3'>4</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(game_info, f)\n",
      "\u001b[1;32m/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb Cell 46'\u001b[0m in \u001b[0;36mpull_game_info\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000046?line=16'>17</a>\u001b[0m games_info \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000046?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000046?line=19'>20</a>\u001b[0m     game_i \u001b[39m=\u001b[39m scrape_game_info(i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000046?line=20'>21</a>\u001b[0m     games_info\u001b[39m.\u001b[39mappend(game_i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000046?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(games_info) \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# Progress bar\u001b[39;00m\n",
      "\u001b[1;32m/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb Cell 16'\u001b[0m in \u001b[0;36mscrape_game_info\u001b[0;34m(game_id)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=13'>14</a>\u001b[0m session\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39mhttps://\u001b[39m\u001b[39m'\u001b[39m, adapter)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=15'>16</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://statsapi.web.nhl.com/api/v1/game/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(game_id)\u001b[39m}\u001b[39;00m\u001b[39m/feed/live\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=16'>17</a>\u001b[0m resp \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=17'>18</a>\u001b[0m json_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(resp\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=19'>20</a>\u001b[0m \u001b[39m# RETRIEVE INFO REQUIRED\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickpetanca/projects/nhl_analysis/scripts/1_scrape_data.ipynb#ch0000015?line=21'>22</a>\u001b[0m \u001b[39m# retrieve date and convert to date time\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py:542\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=533'>534</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=534'>535</a>\u001b[0m \n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=535'>536</a>\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=536'>537</a>\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=537'>538</a>\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=540'>541</a>\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=541'>542</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=523'>524</a>\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=524'>525</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=525'>526</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=526'>527</a>\u001b[0m }\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=527'>528</a>\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=528'>529</a>\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=530'>531</a>\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=641'>642</a>\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=643'>644</a>\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=644'>645</a>\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=646'>647</a>\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/sessions.py?line=647'>648</a>\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=437'>438</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=438'>439</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=439'>440</a>\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=440'>441</a>\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=441'>442</a>\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=442'>443</a>\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=443'>444</a>\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=444'>445</a>\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=445'>446</a>\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=446'>447</a>\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=447'>448</a>\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=448'>449</a>\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=449'>450</a>\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=450'>451</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=452'>453</a>\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=453'>454</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/requests/adapters.py?line=454'>455</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=699'>700</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=701'>702</a>\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=702'>703</a>\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=703'>704</a>\u001b[0m     conn,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=704'>705</a>\u001b[0m     method,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=705'>706</a>\u001b[0m     url,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=706'>707</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=707'>708</a>\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=708'>709</a>\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=709'>710</a>\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=710'>711</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=712'>713</a>\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=713'>714</a>\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=714'>715</a>\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=715'>716</a>\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=716'>717</a>\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=443'>444</a>\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=444'>445</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=445'>446</a>\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=446'>447</a>\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=447'>448</a>\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=448'>449</a>\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=449'>450</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=450'>451</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=440'>441</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=441'>442</a>\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=442'>443</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=443'>444</a>\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=444'>445</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=445'>446</a>\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=446'>447</a>\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=447'>448</a>\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/site-packages/urllib3/connectionpool.py?line=448'>449</a>\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=1345'>1346</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=1346'>1347</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=1347'>1348</a>\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=1348'>1349</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=1349'>1350</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=313'>314</a>\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=314'>315</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=315'>316</a>\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=316'>317</a>\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=317'>318</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=275'>276</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=276'>277</a>\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=277'>278</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/http/client.py?line=278'>279</a>\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1236'>1237</a>\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1237'>1238</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1238'>1239</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1239'>1240</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1240'>1241</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1241'>1242</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1242'>1243</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1096'>1097</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1097'>1098</a>\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1098'>1099</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1099'>1100</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nhl_analysis/lib/python3.8/ssl.py?line=1100'>1101</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%% scrape game info\n",
    "game_info = pull_game_info(game_ids)\n",
    "with open('/Users/patrickpetanca/projects/nhl_analysis/data/games_info.pkl', 'wb') as f:\n",
    "    pickle.dump(game_info, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "702c16d30426216c846babaa6d6b366fbd94b1312ec71aa5e7fdeb6b891ffae1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nhl_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
